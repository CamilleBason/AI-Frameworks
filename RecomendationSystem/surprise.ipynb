{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wikistat/AI-Frameworks/blob/master/IntroductionDeepReinforcementLearning/Policy_Gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IA Frameworks](https://github.com/wikistat/AI-Frameworks) - Introduction to Recommendation System with Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Collaborative Filtering with `Surprise` Python Library.\n",
    "\n",
    "The objectives of this notebook are the following : \n",
    "\n",
    "* Discover and Explore `MovieLens` Dataset\n",
    "* Discover `Surprise`python library\n",
    "* Use neighborhood-based methods (User-User and Item-Item Filters) methods to learn similarity between users and between items. Use it to apply recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & Data (Google Colab)\n",
    "\n",
    "If you're running this notebook on Google colab, you do not have access to the `solutions` folder you get by cloning the repository locally. \n",
    "\n",
    "The following lines will allow you to build the folders and the files you need for this TP.\n",
    "\n",
    "**WARNING 1** Do not run this line localy. <br>\n",
    "**WARNING 2** The magic command `%load` does not work work on google colab, you will have to copy-paste the solution on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir solutions\n",
    "! wget -P solutions https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/solutions/more_complaisant_harsh_user.py\n",
    "! wget -P solutions https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/solutions/top10.py\n",
    "! wget -P solutions https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/solutions/user_user_similarity_matrix.py\n",
    "! wget -P solutions https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/solutions/10_most_recommended_movies.py\n",
    "! wget -P solutions https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/solutions/train_full_dataset.py\n",
    "! mkdir movielens_small\n",
    "https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/movielens_small/movies.csv\n",
    "https://github.com/wikistat/AI-Frameworks/raw/master/RecomendationSystem/movielens_small/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import surprise\n",
    "import surprise.prediction_algorithms as spa\n",
    "\n",
    "#Plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sb\n",
    "sb.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data : Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `movielens` dataset is a famous and widely used dataset furnish by *GroupLens* company : (https://grouplens.org/).\n",
    "\n",
    "The dataset is composed of ratings of movies made by a set of users collected over various periods of time. \n",
    "\n",
    "They are various datasets of different size available on their website : https://grouplens.org/datasets/movielens/.  \n",
    "\n",
    "We will used, all along the different TPs of this lab, the small dataset (100k ratings) for test and exploration and the stable dataset (25 Millions ratings) for testing performances. \n",
    "\n",
    "\n",
    "* Small Dataset -  *movielens_small folder (ON AI-FRAMEWORKS GITHUB)* \n",
    "    * 100,000 ratings. \n",
    "    * 9742 movies. \n",
    "    * 610 users.\n",
    "\n",
    "\n",
    "* Stable Dataset - *DOWNLOAD LINK AT THE END OF THE TP* \n",
    "    * 20 million ratings.\n",
    "    * 59.047 movies.\n",
    "    * 162.541 users.\n",
    "    \n",
    "Those datasets are also composed of metadata about the movie (type, tags on the movie) and bout the users (age, sex, ..), that can be used to improve the recommendation system. We won't use those data as the methods we cover in the course does not handle metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings\n",
    "The `ratings.csv`files is composed of fours columns:\n",
    "\n",
    "* userId : Int. Unique id of the user.\n",
    "* movieId : Int. Unique id of the movie.\n",
    "* rating : Int(0-5). Rate given by an user to a movie.\n",
    "* timestamp : Int. Time at which the rate has been given by. \n",
    "\n",
    "We won't use *timestamp* columns during this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"movielens_small/\"\n",
    "rating = pd.read_csv(DATA_DIR + \"ratings.csv\")\n",
    "nb_entries = rating.shape[0]\n",
    "print(\"Number of entries : %d \" %nb_entries)\n",
    "rating.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_user = len(rating.userId.unique())\n",
    "print(\"Number of unique User : %d\" %nb_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_movie = len(rating.movieId.unique())\n",
    "print(\"Number of unique Movies : %d\" %nb_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies\n",
    "\n",
    "The `movies.csv`files is composed of three columns:\n",
    "\n",
    "* movieId : Int. Unique id of the movie.\n",
    "* title : String. The title of the movie.\n",
    "* genres : String. The genre(s) of the movies.\n",
    "\n",
    "We won't use *genres* columns during this lab. We won't use title in our algorithm but we will use it to display information and give more sense to our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(DATA_DIR + \"movies.csv\")\n",
    "print(\"Number of movies in the dictionary : %d\" %(len(movies.movieId.unique())))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `id_to_title` dictionary to convert id to their title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_title = dict(movies[[\"movieId\",\"title\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a *movie* columns to the rating dataset in order to display directly this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating[\"movie\"] = [id_to_title[x] for x in rating[\"movieId\"].values]\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "Let's make some quick exploration to have some intuitions about these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User\n",
    "We look at the distribution number of rating per user. We create a *groupby* pandas object where row are group by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_gb_user = rating.groupby(\"userId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of rating per user.\n",
    "\n",
    "We will display the distribution of number of rating per user.\n",
    "\n",
    "Plot are display using:\n",
    "* **Seaborn**: A library based on *matplotlib* that can easily enable more beautiful an readable plot.\n",
    "* **Plotly** :   A library available in python, javascript or R which allow to build interactive graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rating_gb_user.count()[\"rating\"].values\n",
    "fig = plt.figure(figsize=(30,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.distplot(x, ax=ax, kde=False, bins = np.arange(x.min(),x.max()+5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rating_gb_user.count()[\"rating\"].values\n",
    "data = [go.Histogram(x=x,\n",
    "                    xbins=dict( # bins used for histogram\n",
    "                    start=x.min(),\n",
    "                    end=x.max(),\n",
    "                    size=5,\n",
    "                ))]\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(\n",
    "    title_text='Number of rate per user distribution', # title of plot\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1 # gap between bars of the same location coordinates\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the distribution? What is the minimum number of rate a user has given?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Find the most *complaisant*  and the most *harsh* users and display their notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/more_complaisant_harsh_user.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most \"Hard\" user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie\n",
    "We look at the distribution number of rating received per movie. We create a *groupby* pandas object where row are group by movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_gb_movie = rating.groupby(\"movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of rating per movie.\n",
    "We will display the distribution of number of rating per user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rating_gb_movie.count()[\"rating\"].values\n",
    "fig = plt.figure(figsize=(30,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.distplot(x, ax=ax, kde=False, bins = np.arange(x.min(),x.max()+5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rating_gb_movie.count()[\"userId\"].values\n",
    "data = [go.Histogram(x=x,\n",
    "                    xbins=dict( # bins used for histogram\n",
    "                    start=x.min(),\n",
    "                    end=x.max(),\n",
    "                    size=2,\n",
    "                ))]\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(\n",
    "    title_text='Number of rate per movie', # title of plot\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1 # gap between bars of the same location coordinates\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the distribution of the movie? What is the minimum number of rate a movie can have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercices** Display the Top 10 most rated movies, top 10 better and worst movies (for movies with at least 10 rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/top10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suprise library\n",
    "\n",
    "<a href=\"http://surpriselib.com/\" ><img src=\"http://surpriselib.com/logo_white.svg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"Surprise\"/></a> \n",
    "\n",
    "\n",
    "Surprise is a python library http://surpriselib.com/, that contains various algorithm dedicated to Recommendation.  We will use it to apply neighborhood-based algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise contains various function that enable to load directly the **movielens** dataset and create train/test partition. However we won't use those methods in order to retrieve the same train/test partition using other libraries.\n",
    "\n",
    "The movielens-100K dataset is changing and we want it to be the same to compare the methods with different library over the notebooks of this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_train,rating_test = train_test_split(rating, test_size=0.1, random_state=42)\n",
    "print(\"N train rates : %d\"%rating_train.shape[0])\n",
    "print(\"N test rates : %d\"%rating_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surprise** use their own type of object `Trainset` on which their algorithms are trained\n",
    "\n",
    "To build it we first use the `load_from_df` methods that require data Nx3 matrices where N is the number of entries and the 3 columns are the users, the items and the rates. This correspond to the rating dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = surprise.Reader(rating_scale=(0, 5))\n",
    "data = surprise.Dataset.load_from_df(rating_train[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the `build_full_trainset` to convert the Surprise Dataset object to a Surprise Trainset object that can be fitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.build_full_trainset()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset can be a simple python list with the same three arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list([tuple(x) for x in rating_test[['userId', 'movieId', 'rating']].values])\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-User Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main assumption** : customers with a similar profile will have similar tastes.\n",
    "\n",
    "\n",
    "For a customer u, the aim is to \n",
    "* find a subset of customers with a close profile \n",
    "* predicting the missing mark of a product i on customer u with a convex linear aggregation of marks of customers with close profile.\n",
    "\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\bar{r}_u + \\frac{\\sum_{u'\\in S_u} s(u,u')\\cdot (r_{u',i}-\\bar{r_{u'}})}{\\sum_{u'\\in S_u} |s(u,u')| }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the User-User similarity Matrix\n",
    "\n",
    "Have a look ad the surprise \"knn inspired\" algorithm documentation :  https://surprise.readthedocs.io/en/stable/knn_inspired.html to understand the different algorithm available.\n",
    "\n",
    "**Exercise** :  Initialize a method that perform a **user-user** filter based on the formula above (i.e. that **take means** into account) with:\n",
    "* **pearson** similarity distance\n",
    "* **k** (number of neighboor) to 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUFilter = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/user_user_similarity_matrix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can know easily fit the algorithm and compute the results on test with the dedicated `surprise` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "UUFilter.fit(train)\n",
    "predictions = UUFilter.test(test)\n",
    "\n",
    "# Then compute RMSE\n",
    "surprise.accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the User-User similarity Matrix\n",
    "\n",
    "One of the advantage of this methods is that it quite easy to explore the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest user\n",
    "\n",
    "The surprise library furnish a `get_neighbors` method that allows you to get directly the closest id of a given id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId=1\n",
    "nearest_userId = UUFilter.get_neighbors(userId,k=1)[0]\n",
    "print(\"user %d is the closest user of user %d\" %(nearest_userId,userId))\n",
    "print(\"User %d\" %userId)\n",
    "display(rating[rating.userId==userId][[\"movie\",\"rating\"]].sort_values(by=\"rating\"))\n",
    "print(\"User %d\" %nearest_userId)\n",
    "rating[rating.userId==nearest_userId][[\"movie\",\"rating\"]].sort_values(by=\"rating\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "\n",
    "**Exercise** Build the list of the 10 most recommended movies for the user with the estimated rate. use the `predict`method of the `UUfilter` object that give you the rate for a couple (userId,itemId)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUFilter.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/10_most_recommended_movies.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Item Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main assumption : the customers will prefer products that share a high similarity with those already well appreciated. \n",
    "\n",
    "For a item i, the aim is to \n",
    "* find a subset of product with a close profile \n",
    "* predicting the missing mark of a product i on customer u with a convex linear aggregation of marks of items with close profile of the same customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{r}_{ui} = \\mu_i + \\frac{ \\sum\\limits_{j \\in N^k_u(i)}\n",
    "\\text{sim}(i, j) \\cdot (r_{uj} - \\mu_j)} {\\sum\\limits_{j \\in\n",
    "N^k_u(i)} \\text{sim}(i, j)}$$\n",
    "\n",
    "We just have one parameter to change (user_based=False) in order to perform Item-Item Filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IIFilter = spa.knns.KNNWithMeans(k=40, \n",
    "                      min_k =1, \n",
    "                      sim_options = {'name': 'pearson',\n",
    "                                     'user_based': False},\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "IIFilter.fit(train)\n",
    "predictions = IIFilter.test(test)\n",
    "\n",
    "# Then compute RMSE\n",
    "surprise.accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions** The method is quite slower than the previous one. Why is that? \n",
    "What can you say about the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an example prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Item-Item similarity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest user\n",
    "\n",
    "The same `get_neighbors` can be used and now show closest item of a given item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieId = 2\n",
    "print(\"Selected Movie : %s\" %(id_to_title[movieId]))\n",
    "nearest_movieId = IIFilter.get_neighbors(movieId,k=10)\n",
    "print(\"10 most similar movies\")\n",
    "pd.DataFrame([id_to_title[k] for k in nearest_movieId if k in id_to_title])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction \n",
    "\n",
    "Same code that above can be used to recommend 10 movies to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId=1\n",
    "# Get list of movies already rated by the user\n",
    "idmovies_rated_per_user = rating[rating.userId==userId][\"movieId\"].values\n",
    "# get prediction fo all movies for movies that are not already rated\n",
    "predicted = [[mid,IIFilter.predict(userId, mid)] for mid in movies.movieId.values if not(mid in idmovies_rated_per_user)]\n",
    "# sort predicted list according to the estimation computed\n",
    "recommendation = sorted(predicted, key=lambda x : x[1].est, reverse=True)\n",
    "#display the most 10 prediciton with a dataframe\n",
    "pd.DataFrame([(id_to_title[r[0]], r[1].est) for r in recommendation[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results for different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parameters\n",
    "results = []\n",
    "for k in [10,25,50,100]:\n",
    "    for user_based in [True, False]:\n",
    "        for sim_options_name in [\"pearson\",\"cosine\",\"msd\"]:\n",
    "            tstart = time.time()\n",
    "            Filter = spa.knns.KNNWithMeans(k=k,\n",
    "                                  sim_options = {'name': sim_options_name,\n",
    "                                                 'user_based': user_based}, \n",
    "                                verbose=0)\n",
    "            Filter.fit(train)\n",
    "            predictions = Filter.test(test)\n",
    "            rmse = surprise.accuracy.rmse(predictions)\n",
    "            results.append([k, user_based, sim_options_name, rmse])\n",
    "            tend = time.time()\n",
    "            print(\"%s, %s, %s computed in %d seconds\" %(k, user_based, sim_options_name, tend-tstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "color_dict = {True:\"green\",False:\"red\"}\n",
    "marker_dict = {\"pearson\":\"x\",\"cosine\":0,\"msd\":\"triangle-up\"}\n",
    "for user_based in [True, False]:\n",
    "    for sim_options_name in [\"pearson\",\"cosine\",\"msd\"]:\n",
    "        result_ = [r for r in results if r[1]==user_based and r[2] == sim_options_name]\n",
    "        x = [r[0] for r in result_]\n",
    "        y = [r[3] for r in result_]\n",
    "        user_string = \"User_User\" if user_based else \"Item Item\"\n",
    "        \n",
    "        data.append(go.Scatter(x=x,\n",
    "                               y=y,\n",
    "                               marker =dict(color=color_dict[user_based], symbol=marker_dict[sim_options_name], size=10),\n",
    "                               name = \"%s Filter with %s similarity\" %(user_string, sim_options_name)\n",
    "                        ))\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(\n",
    "    title_text='MSE according to parameters',\n",
    "    width=10\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "color_dict = {True:\"green\",False:\"red\"}\n",
    "marker_dict = {\"pearson\":\"x\",\"cosine\":\".\",\"msd\":\"^\"}\n",
    "for user_based in [True, False]:\n",
    "    for sim_options_name in [\"pearson\",\"cosine\",\"msd\"]:\n",
    "        result_ = [r for r in results if r[1]==user_based and r[2] == sim_options_name]\n",
    "        x = [r[0] for r in result_]\n",
    "        y = [r[3] for r in result_]\n",
    "        user_string = \"User_User\" if user_based else \"Item Item\"\n",
    "        ax.plot(x,y, color=color_dict[user_based], marker = marker_dict[sim_options_name], markersize=10, label = \"%s Filter with %s similarity\" %(user_string, sim_options_name))\n",
    "ax.set_title(\"MSE according to parameters\", fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Which algorithm perform the best? With which parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see that these results are not that bad compare to other methods. \n",
    "However, this method would take to many time and requires to many computation power to be applied on the complete dataset of (25 Millions of row). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optionnal)Run code on complete dataset \n",
    "\n",
    "**Exercise**\n",
    "\n",
    "* Download the complete and stable dataset by clicking here : http://files.grouplens.org/datasets/movielens/ml-25m.zip. \n",
    "* Move the dataset to the current file (RecomendationSystem).\n",
    "* Load the data and create a train/test dataset.\n",
    "* Fit a neighborhood based algorithm with the best parameter according to the results find on small dataset (**It may take a while**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/train_full_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart=time.time()\n",
    "IIFilter = spa.knns.KNNWithMeans(k=100, \n",
    "                      min_k =1, \n",
    "                      sim_options = {'name': 'msd',\n",
    "                                     'user_based': False},\n",
    "                     verbose=1)\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "IIFilter.fit(train)\n",
    "predictions = IIFilter.test(test)\n",
    "\n",
    "# Then compute RMSE\n",
    "surprise.accuracy.rmse(predictions)\n",
    "tend=time.time()\n",
    "print(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization Based Algorithm\n",
    "\n",
    "* The surprise library contains only [one implementation](Zhang et al. [2006], Luo et al. [2014]) of NMF algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMFmodel = spa.matrix_factorization.NMF(n_factors=20, \n",
    "                      n_epochs =50)\n",
    "NMFmodel.fit(train)\n",
    "predictions = NMFmodel.test(test)\n",
    "\n",
    "# Then compute RMSE\n",
    "surprise.accuracy.rmse(predictions)\n",
    "tend=time.time()\n",
    "print(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
