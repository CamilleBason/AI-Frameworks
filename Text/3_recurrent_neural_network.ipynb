{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement Naturel du Langage (NLP) : Génération de Texte avec des Réseaux Récurrent. \n",
    "\n",
    "Au cours de ce calepin, nous allons voir comment générer des description de produits à l'aide de Réseaux Récurents et notamment grace aux structure LSTM (Long-Short Term Memory). \n",
    "\n",
    "L'intérêt de cette application est limité. Les descriptions de textes de ce document sont trop pauvres syntaxiquement pour pouvoir juger réellement de la qualité du texte généré. L'intérêt réel de ce calepin est de voir comment les données doivent être mis en forme pour être utilisé dans un réseau recurrent dans un but de génération de texte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo \n",
    "* Text generation is one to many\n",
    "* add classification (many to one)\n",
    "* marque prediction? many to many?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des librairies utilisées\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données\n",
    "\n",
    "La Catégorie de Niveau 3 `COQUE - BUMPER - FACADE TELEPHONE` est la catégorie le plus représenté du jeu de données originale **Cdiscount** avec  2.184.671 déscriptions présentent.  Parmis ces descriptions, 1.761.637 sont composés d'exactement 197 caractères. \n",
    "\n",
    "Nous allons nous servir de ces lignes (ou un sous ensemble de ces lignes, en fonction de la puissance de calcul disponible sur votre machine) pour apprendre un modèle de génération de texte qui permettra de généré automatiquement une nouvelle description de ce type de produit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "DATA_DIR = \"\"\n",
    "X = np.load(DATA_DIR+\"data/description_coque.npy\")[:N]\n",
    "print(X.shape)\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Vérifiez que toutes les séquences sont bien de tailles 197."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd=197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme  des données\n",
    "\n",
    "La génération de texte implique de constuire un réseau `One-To_Many` :\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wikistat/AI-Frameworks/master/slides/OneToMany.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Ou la prédiction $y_t$ servira d'entrée au réseau au temps $t+1$, i.e : $y_t=x_{t+1}$. \n",
    "\n",
    "Chaque $x_t$ représente ici un caractère de la déscription encodé en One-Hot encoding. Ainsi une description $x$ composé de $N_d$ caractères sera modélisé par une matrice de taille $(N_v\\times N_d)$  $x=[x_1,x_2,...,x_{N_d}]$  ou $x_i \\in \\mathbb{R}^{N_v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la liste des caractères\n",
    "\n",
    "Afin d'encoder les description sous format 'One-Hot encoding'  nous devons dans un premier temps retrouver la taille $Nv$ de notre vocabulaire constitué de tout les caractères présent dans la description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(functools.reduce(lambda x,y : x.union(y), [set(x) for x in X], set()))\n",
    "print(\"Vocabulaire : \" +  str(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons à ce vocabulaire deux indicateur permettant de localiser le début et la fin de chaque description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.extend([\"start\",\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nv = len(chars)\n",
    "print(\"Taille du vocabulaire : %d\" %Nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dictionnaires\n",
    "\n",
    "Les dictionnaires `char_to_int` et `int_to_char` permettent respectivement d'encoder une description texte et de décoder un encodage `One-Hot``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = {i:c for i,c in enumerate(chars)}\n",
    "char_to_int = {c:i for i,c in int_to_char.items()}\n",
    "I_START = char_to_int[\"start\"]\n",
    "I_END = char_to_int[\"end\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des Descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante, permet d'encoder une matrice $X\\in \\mathbb{R}^{N \\times N_d}$ constitués de *N* descriptions en une matrice $X_{vec} \\in \\mathbb{R}^{N \\times N_d \\times N_v}$ contenant les description encodées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_output_sequence(x, length_sequence, size_vocab, char_to_int_dic, i_start, i_end):\n",
    "    n = x.shape[0]\n",
    "    x_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    y_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    x_vec[:,0,i_start] = 1\n",
    "    y_vec[:,-1,i_end] = 1\n",
    "    for ix,x in tqdm(enumerate(x)):\n",
    "        for ic,c in enumerate(x):\n",
    "            c_int = char_to_int_dic[c]\n",
    "            x_vec[ix,ic+1,c_int]=1\n",
    "    y_vec[:,:-1,:] = x_vec[:,1:,:] \n",
    "    return x_vec, y_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec, Y_vec = encode_input_output_sequence(X[:N], Nd+1, Nv, char_to_int,I_START,I_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Retrouvez la phrase originale de la phrase test affiché ci-dessous à partir de la phrase encodé. Vérifiez que x et y sont bien les mêmes descriptions seulement décalées d'un index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/3_1.py\n",
    "i_test = 50\n",
    "print(X[50])\n",
    "def decode_sequence(x, int_to_char_dic):\n",
    "    seq = []\n",
    "    for i in np.where(x)[1]:\n",
    "        seq.append(int_to_char_dic[i])\n",
    "    return \"\".join(seq)\n",
    "decode_sequence(X_vec[50], int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage\n",
    "\n",
    "Nous allons maintenant définir notre modèle récurrent afin de générer notre modèle de prédiction. \n",
    "\n",
    "Prenez le temps de bien comprendre toutes les fonctions et arguments utilisés pour construire ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_hidden = 32\n",
    "epochs = 20\n",
    "batch_size= 128\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(nb_hidden, input_shape=(None, Nv), return_sequences=True))\n",
    "model.add(kl.TimeDistributed(kl.Dense(Nv)))\n",
    "model.add(kl.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "model.fit(X_vec, Y_vec, epochs=epochs, batch_size=batch_size)\n",
    "model.save(\"data/generate_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Pourquoi est-ce la `categorical_crossentropy` qui est utilisée comme fonction de perte?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de Texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celulle suivante permet de générer une description produit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.zeros((1, Nd+1, Nv))\n",
    "print(\"step 0\")\n",
    "x_pred[0,0,I_START] =1\n",
    "x_pred_str = decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)\n",
    "\n",
    "for i in range(Nd):\n",
    "    ix = np.argmax(model.predict(x_pred[:,:i+1,:])[0][-1,:])\n",
    "    x_pred[0,i+1,ix] = 1\n",
    "x_pred_str=decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment cette génération est-elle produite? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Effectuez une génération en choissisant la ou les premières lettres qui seront générées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/3_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Effectuez une génération en ajoutant de l'aléa. Vous pouvez par exemple faire en sorte que chaque lettre soit séléctionnée selon une loi multinomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/3_3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
