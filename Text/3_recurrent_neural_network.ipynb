{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IA Frameworks](https://github.com/wikistat/AI-Frameworks) - Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data : Cdiscount's product description.\n",
    "\n",
    "This dataset has been released from Cdiscount for a data competition (type kaggle) on the french website [datascience.net](https://www.datascience.net/fr/challenge). <br>\n",
    "The test dataset of this competition has not been released, so we used a subset of 1M producted of the original train dataset(+15M rows) all along the **Natural Language Processing** lab.<br>\n",
    "The objective of this competition was to classify the text description of various product into various categories that compose the navigation tree of Cdiscount website. It is composed of 4,733 categories organized within 44 meta categories. <br>\n",
    "\n",
    "The objective of this lab is not win the competition so we will only used the meta-categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Recurrent Neural Network. Application to text classification and text generation\n",
    "\n",
    "In this second notebook we study how to use a recurrent neural network (RNN) for two use case:\n",
    "\n",
    "* Text classification : As the two precedent notebook, we will use Recurrent Neural Network algorithm to predict product's category.\n",
    "* Text Generation: We will see how to generate product description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo \n",
    "* Text generation is one to many\n",
    "* add classification (many to one)\n",
    "* marque prediction? many to many?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import pickle\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial\n",
    "\n",
    "This part aims to understand how to build the different types of RNN models (**one/many-to-one/many**) with `keras`.\n",
    "\n",
    "The example are stricly pedagogical and wouldn't need such a models to be built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many to one\n",
    "\n",
    "**Many-to-one** recurrent neural network take a sequence as an input and return a scalar as an output :\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_one.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example\n",
    "\n",
    "Let's take an example where the *input* are sequences of 3 numbers and the output the sum of these 3 numbers.\n",
    "\n",
    "Hence the dimensions of the input matrix *X* will be of size:\n",
    "\n",
    "* N: Number of sequences = 100 (arbitrary values), \n",
    "* Timestep: (Size of sequences) = 3, \n",
    "* Number of features (How many features for each element of the sequences) = 1 \n",
    "\n",
    "*NB*: by default, keras handle the dimensions of the input in that order : N_batch, Timestep and Features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of input sequences: 100, Timestep: 3, Number of features: 1\n",
      "Dimensions of input sequences: 100, Timestep: 1, Number of features: 1\n",
      "Input Example\n",
      "[[0]\n",
      " [1]\n",
      " [2]]\n",
      "Output Example\n",
      "[[3]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(300).reshape(100,3,1)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %X.shape)\n",
    "Y = X.sum(1).reshape(100,1,1)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %Y.shape)\n",
    "print(\"Input Example\")\n",
    "print(X[0])\n",
    "print(\"Output Example\")\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "The following lines enable to define a very simple model with one **many-to-one** *RNN* layer with:\n",
    "\n",
    "* 10 neurons (*units=10)\n",
    "* a *relu* activation layer\n",
    "\n",
    "This model take as an input sequences of size (3,1). Note that the *input_shape* argument does not take the batch size as an input. Only the *timestep* and the *feature sie*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 10)                120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Do the shape of the output seems normal to you? What do the two dimensions represent? <br>\n",
    "**Exercise** : Send a sequence trough the model and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/simple_rnn_output.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the complete model. As the output of the RNN layer is a vector with 10 features, let's add a Dense layer so that the output is of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1)))\n",
    "model.add(kl.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model with and *adam* optimizer and a *mse* as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff251251160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the model can now correctly perform the sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.83401]]\n",
      "[[48.56091]]\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array([10,11,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([10,25,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if  input_shape = (1,1) we set a **one-to-one** recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With no fix timestep\n",
    "\n",
    "Note that in the previous example, the timestep was fix to three. But it's possible to set the parameters to *None* so that the model can handle sequences of variable length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(None, 1)))\n",
    "model.add(kl.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the model can handle sequence of variable lengths, during training, all sequences should have same lengths.\n",
    "\n",
    "To handle this, we apply zero padding to the sequences of variables length so that it does not affect the results thanks to the `pad_sequences` function from `keras`.\n",
    "\n",
    "Let's first create a X list of sequences of different size (3 or 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 100, 2: 100})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for x in np.arange(0,300,3):\n",
    "    X.append([x,x+1,x+2])\n",
    "for x in np.arange(300,500,2):\n",
    "    X.append([x,x+1])\n",
    "collections.Counter([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now pad this sequence with zero values. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (200,3)\n",
      "3 first sequences\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "2 last sequences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0, 494, 495],\n",
       "       [  0, 496, 497],\n",
       "       [  0, 498, 499]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, value=0.0, padding = 'pre')\n",
    "print(\"X shape : (%d,%d)\" %X.shape)\n",
    "print(\"3 first sequences\")\n",
    "print(X[:2])\n",
    "print(\"2 last sequences\")\n",
    "X[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a good practices aims to pad value to the **left** of the sequences. <br>\n",
    "This can be not intuitive but The reason is that nothing is learn as the beginning of the sequence because all the values would be zeros, the real learning would start when first non zeros values appears. <br>\n",
    "If the sequences are padded to the right, the information learn on the beginning of the sequences could be lost passing through all zeros values at the end of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff2444065f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(200,3,1)\n",
    "Y = X.sum(1)\n",
    "\n",
    "epochs = 500\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict sum of sequences of different lenght (even bigger sequences, but results is not guaranted!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.3284464]]\n",
      "[[12.905861]]\n",
      "[[19.715675]]\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array([3,4]).reshape(1,2,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([3,4,5]).reshape(1,3,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([3,4,5,6]).reshape(1,4,1)\n",
    "print(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many to Many\n",
    "\n",
    "**Many-to-many** recurrent neural network take a sequence as an input and return a sequence as an output :\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example\n",
    "\n",
    "Let's take an example where the *input* are sequences of 3 number  and the output will be a sequences of cumulative sum, i.e.\n",
    "\n",
    "* input = [x1, x2, x3]\n",
    "* output = [x1, x1+x2, x1+x2+x3]\n",
    "\n",
    "\n",
    "Hence BOTH the dimensions of the input *X* AND the output *Y*  matrices will be of size:\n",
    "\n",
    "* N: Number of sequences = 100 (arbitrary values), \n",
    "* Timestep: (Size of sequences) = 3, \n",
    "* Number of features (How many features for each element of the sequences) = 1,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of input sequences: 100, Timestep: 3, Number of features: 1\n",
      "Dimensions of input sequences: 100, Timestep: 3, Number of features: 1\n",
      "Input Example\n",
      "[[0]\n",
      " [1]\n",
      " [2]]\n",
      "Output Example\n",
      "[[0]\n",
      " [1]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(300).reshape(100,3,1)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %X.shape)\n",
    "Y = X.cumsum(1).reshape(100,3,1)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %Y.shape)\n",
    "print(\"Input Example\")\n",
    "print(X[0])\n",
    "print(\"Output Example\")\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "The following lines enable to define a very simple model with one **many-tom-many** *RNN* layer with:\n",
    "\n",
    "* 10 neurons (*units=10)\n",
    "* a *relu* activation layer\n",
    "\n",
    "This model take as an input sequences of size (3,1) and return a sequence of the same size.<br>\n",
    "This is specified but the *return_sequences* argument wich is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 3, 10)             120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Do the shape of the output seems normal to you? What do the three dimensions represent? <br>\n",
    "**Exercise** : Send a sequence trough the model and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/simple_rnn_output_bis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the complete model. <br>\n",
    "For each input sequences, the output of the RNN layer is a matrix of size 3 (number of timestep) per 10  (features). <br>\n",
    "The desired output would be a sequence of size 3  per 1.\n",
    "\n",
    "In order to obtain the correct dimension let's add a Dense layer at each timestep of the output wit the help of the `TimeDistributed` layer of `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 3, 10)             120       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 3, 1)              11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1), return_sequences=True))\n",
    "model.add(kl.TimeDistributed(kl.Dense(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model with and *adam* optimizer and a *mse* as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff230619940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the model can now correctly perform the cumulative sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[11.015212]\n",
      "  [22.416029]\n",
      "  [34.805275]]]\n",
      "[[[11.015212]\n",
      "  [36.086624]\n",
      "  [50.15926 ]]]\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array([10,11,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([10,25,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as previously seen, it would been possible to set the *timestep* parameters to *None* so that the model can compute cumulative sum of model whatever the size of their length.  \n",
    "This could be a good **exercise** if you want to practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One to Many\n",
    "\n",
    "**One-to-many** recurrent neural network take a scalar as an input and return a sequence as an output. \n",
    "\n",
    "There are different ways to define **one-to-many**\n",
    "neural network. \n",
    "\n",
    "* In the example below, the **one-to-many** network can be seen as as a **many-to-many** neural network where the input sequence is build iteratively.\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/one_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "* It would also be possible to only pass an input at the first timestep. Then **one-to-many** network can be seen as as a **many-to-many** neural network where the input sequence is composed of one scalar and `None` entry to fill the sequences. \n",
    "\n",
    "Hence, **one-to-many** networks, can be seen as particular case of **many-to-many** neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example\n",
    "\n",
    "Let's take an example where the *input* are scalar and the output is sequence of 3 number composed such that\n",
    "\n",
    "* input = x\n",
    "* output = [x+2, x+4, x+6]\n",
    "\n",
    "Hence the dimensions of the output matrix *Y* will be of size:\n",
    "\n",
    "* N: Number of sequences = 100 (arbitrary values), \n",
    "* Timestep: (Size of sequences) = 3, \n",
    "* Number of features (How many features for each element of the sequences) = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "At **training**  the keras model will be built as a **many-to-many** models. <br>\n",
    "Indeed as you now the sequence output you're expect to get, you now the sequence that will be send as an input you want to learn. IN the example above:\n",
    "\n",
    "* input = [x,x+2,x+4].\n",
    "* output = [x+2,x+4,x+6]\n",
    "\n",
    "**Exercise**: Build the toy dataset and the models that will learn how to predict the output sequences from and input sequences.<br>\n",
    "**nb** Remember that at prediction, the model should be able to take a scalar as an input (i.e. a sequence of one timestep).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/one_to_many_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff2007456d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solution/one_to_many_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Once your model is build, write a function that build a the 3 numbers sequences output from a scalar input using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input scalar : 10. Output sequences: [11.660, 13.331, 15.012]\n"
     ]
    }
   ],
   "source": [
    "# %load solution/one_to_many_prediction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the examples details so far have treated *one-size* features sequences in order to make this tutorial easier. \n",
    "\n",
    "All of these examples can be easily traduced to *several-size* features length. Let's check that with example on the **Cdisocunt** Dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN layers\n",
    "\n",
    "Once you know how to manipulate the structure defined above, it is really easy to build more complex or deepest RNN model with keras.\n",
    "\n",
    "* `GRU` and `LSTM` can be used the exact same way than `SimpleRNN`in the example above.\n",
    "* Bi-directional layers can be build using the `Bidirectional` layer on `RNN`layer.\n",
    "* Deep RNN can be build adding `RNN` layer like any other sequential model.\n",
    "\n",
    "***Example***:\n",
    "Here is how to build a model with one *LSTM* layer follow by a bidirectional *GRU* layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 3, 10)             480       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 3, 20)             1320      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 3, 1)              21        \n",
      "=================================================================\n",
      "Total params: 1,821\n",
      "Trainable params: 1,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(units=10 ,activation=\"relu\", input_shape=(3, 1), return_sequences=True))\n",
    "model.add(kl.Bidirectional(kl.GRU(units=10 ,activation=\"relu\", return_sequences=True)))\n",
    "model.add(kl.TimeDistributed(kl.Dense(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The Level 3 category `COQUE - BUMPER - FACADE TELEPHONE` is the most represented category within the original **Cdiscount**'s dataset with 2.184.671 descriptions. Among them 1.761.637 are composed with 197 characters. \n",
    "\n",
    "We will now use these lines (or sub-samble of these lines according to the computation power of your machine) in order to learn a text generation model that will allow to automatically generate a new text description of this type of product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "[\"Pour apple iphone 4 : coque bumper silicone blanc - Cet étui en silicone rigide protège et habille votre APPLE iPhone 4. Parfaitement adapté, il permet l'accès à toutes les fo… Voir la présentation\"\n",
      " \"Pour htc one x : coque noire rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de v… Voir la présentation\"\n",
      " \"Pour htc one x : coque blanche rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de… Voir la présentation\"]\n",
      "Size of all the sequences : {197}\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "X = np.load(\"data/description_coque.npy\")[:N]\n",
    "print(X.shape)\n",
    "print(X[:3])\n",
    "print(\"Size of all the sequences : %s\" %(str(set([len(x) for x in X]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns=197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "The text generation implies to build a **one-To_many** model:\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/one_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Where the prediction $y_t$ will be used as an input at time $t+1$, i.e : $y_t=x_{t+1}$. \n",
    "\n",
    "This model with be trained as a **many-to-many**  model. \n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Where the output y will be the same sequence than input x with 1 offset.\n",
    "\n",
    "When using text, the input can be either a word or a characters. As sequences have fixed length, we will use the characters as inputs of the sequences. <br>\n",
    "These characters will be *one-hot encoded* <br>\n",
    "\n",
    "Hence each description $x$ will be represented as a Matrix of size $N_s \\times N_v$ where\n",
    "\n",
    "* $N_s=197$ is the length of the sequences (timestep)\n",
    "* $N_v$ is the size of the vocabulary (the list of caracters) .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters' list\n",
    "\n",
    "Let's first create a list of unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters list of size 87 : ['h', 'd', 'I', 'ç', 'ô', '1', 'e', 'W', 'Z', 'k', 'p', 'Q', '/', 'â', 'f', 'M', '5', 'é', 'P', 'q', 'm', 'J', 'U', 'u', ':', 'r', 'E', 'ê', 'z', 's', 'K', 'c', '3', 'X', 'F', '-', 'n', '(', 'x', '8', 'i', 'O', 'l', ',', \"'\", 'C', 'V', 'S', 'L', 'A', '&', 'D', 'y', '…', 'w', '0', 'N', '%', '2', '.', '6', 'Y', 'G', 'j', 'T', '9', '!', 'v', 'H', 'è', ' ', 'a', 'o', 'à', '*', '4', 'R', ')', '\"', 'g', '7', '\\xa0', '?', 'b', 't', '+', 'B']\n"
     ]
    }
   ],
   "source": [
    "chars_set = list(functools.reduce(lambda x,y : x.union(y), [set(x) for x in X], set()))\n",
    "print(\"Characters list of size %d : %s\"  %(len(chars_set), str(chars_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add two elements to these listes allowing to detect the *start* and the *end* of a sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the vocabulary : 89\n"
     ]
    }
   ],
   "source": [
    "chars_set.extend([\"START\",\"END\"])\n",
    "Nv = len(chars_set)\n",
    "print(\"Total size of the vocabulary : %d\" %Nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence encoding\n",
    "\n",
    "There are no library (or I do not find it), that enable to *one-hot encode* a string at a character level.\n",
    "\n",
    "The following lines enables to apply it.\n",
    "\n",
    "* First `char_to_int` and `int_to_char` dictionary are created, enabling to retrieve the position of a character in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = {i:c for i,c in enumerate(chars_set)}\n",
    "char_to_int = {c:i for i,c in int_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function encode\n",
    "\n",
    "* a  $X\\in \\mathbb{R}^{N \\times N_d}$ matrix composed of *N* text description of size *N_s*   size  \n",
    "into \n",
    "* a $X_{vec} \\in \\mathbb{R}^{N \\times N_d \\times N_v}$ matrix composed of *N* sequences of size $N_s\\times N_v$ (the encoded text description) .\n",
    "\n",
    "and the $Y\\in \\mathbb{R}^{N \\times N_d}$ matrix (which is the same that the $X$ matrix with offset one) to the $Y_{vec} \\in \\mathbb{R}^{N \\times N_d \\times N_v}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_output_sequence(x_descriptions, length_sequence, size_vocab, char_to_int_dic):\n",
    "    # Get the number of description in x.\n",
    "    n = x_descriptions.shape[0]\n",
    "    \n",
    "    # Set the dimensions of the output encoded matrices fill with zero.\n",
    "    # the length_sequence is actually length_sequences\n",
    "    x_vec = np.zeros((n,length_sequence+1, size_vocab))\n",
    "    y_vec = np.zeros((n,length_sequence+1, size_vocab))\n",
    "    \n",
    "    \n",
    "    # Let's now fill the matrices with one at the location of each characters position\n",
    "    \n",
    "    # First let's fill each input sequences with the START position at the begining of the encoded sequences\n",
    "    x_vec[:,0,char_to_int[\"START\"]] = 1\n",
    "    # and the output sequences with the END position at the end of the encoded sequences\n",
    "    y_vec[:,-1,char_to_int[\"END\"]] = 1\n",
    "    # Now let's iterate over all x_descriptions\n",
    "    for ix,x in tqdm(enumerate(x_descriptions)):\n",
    "        # And over each character of the description\n",
    "        for ic,c in enumerate(x):\n",
    "            # For each character `c` we set one at his position in the vocabulary.\n",
    "            c_int = char_to_int_dic[c]\n",
    "            x_vec[ix,ic+1,c_int]=1\n",
    "    # The y-vec matrices is the same than the x matrix with one offset\n",
    "    y_vec[:,:-1,:] = x_vec[:,1:,:] \n",
    "    return x_vec, y_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Be sure to understand each step of these function.\n",
    "\n",
    "Let's apply it on the Descriptions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:12, 8019.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 198, 89)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec, Y_vec = encode_input_output_sequence(X[:N], Ns, Nv, char_to_int)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** \n",
    "* Write a function that enables to retrieve the original phrase from an encoded sequences.\n",
    "* Check that *x* and *y* have actually the same description with one offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Sentences:\n",
      "Pour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentation\n",
      "\n",
      "Decoded input vector::\n",
      "STARTPour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentation\n",
      "\n",
      "Decoded output vector::\n",
      "Pour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentationEND\n"
     ]
    }
   ],
   "source": [
    "# %load solution/decoded_vector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "\n",
    "**Exercise**: Define a simple model (only one LSTM layer with 32 hidden units) that will allow to train the text generation model.\n",
    "*Tips*:\n",
    "* Remember that this model will be used for generation.\n",
    "* What are the dimension of the output? What will be the activation layer? The loss function?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/train_model_text_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have correctly write the model you can observe that it can take a while to obtain convergence when training thise kind of model.\n",
    "\n",
    "Let's download this model, generated with the solution above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"data/generate_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below enable to predict a sentence by iterativaly predict a character sending a previous character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import convert_to_tensor\n",
    "x_pred = np.zeros((1, Ns+1, Nv))\n",
    "print(\"step 0\")\n",
    "x_pred[0,0,char_to_int[\"START\"]] =1\n",
    "x_pred_str = decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)\n",
    "\n",
    "for i in range(Ns):\n",
    "    x_tensor = convert_to_tensor(x_pred[:,:i+1,:])\n",
    "    ix = np.argmax(model.predict(x_tensor)[0][-1,:])\n",
    "    x_pred[0,i+1,ix] = 1\n",
    "x_pred_str=decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** How this prediction is done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Generate a text generation with random first letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/text_generation_random_first_letter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Generate a text generation with some randomness. For example, use a multinomial from the model output to generate a characters at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/text_generation_multinomial.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as sms\n",
    "from solution.clean import CleanText\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from vectorizer import Vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 235/100000 [00:00<00:42, 2346.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 100000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:37<00:00, 2664.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is composed of 100000 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Categorie2</th>\n",
       "      <th>Categorie3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFORMATIQUE</td>\n",
       "      <td>CONNECTIQUE - ALIMENTATION</td>\n",
       "      <td>BATTERIE</td>\n",
       "      <td>Batterie Acer Aspire One 751H-52Yr - Li-Ion 11...</td>\n",
       "      <td>Batterie Acer Aspire One 751H-52Yr</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>batter acer aspir one h yr li ion v mah wh noi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque rigide Bleu lagon pour ALCATEL OT / 6033...</td>\n",
       "      <td>Coque rigide Bleu lagon pour ALCATEL OT / 6033 …</td>\n",
       "      <td>MUZZANO</td>\n",
       "      <td>coqu rigid bleu lagon alcatel ot motif drapeau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Facades et coques CELLULAR LINE SHCKGALS 3 MIN...</td>\n",
       "      <td>Facades et coques CELLULAR LINE SHCKGALS 3 MINIP</td>\n",
       "      <td>CELLULAR LINE</td>\n",
       "      <td>facad coqu cellular lin shckgal minip marqu ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque meteore TPU  LG Nexus 4 / E960</td>\n",
       "      <td>Coque meteore TPU  LG Nexus 4 / E960</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>coqu meteor tpu lg nexus e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque souple Transparente pour LG G FLEX D959 ...</td>\n",
       "      <td>Coque souple Transparente pour LG G FLEX D959 m…</td>\n",
       "      <td>MUZZANO</td>\n",
       "      <td>coqu soupl transparent lg g flex motif keep ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Categorie1                  Categorie2  \\\n",
       "0      INFORMATIQUE  CONNECTIQUE - ALIMENTATION   \n",
       "1  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "2  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "3  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "4  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "\n",
       "                          Categorie3  \\\n",
       "0                           BATTERIE   \n",
       "1  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "2  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "3  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "4  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Batterie Acer Aspire One 751H-52Yr - Li-Ion 11...   \n",
       "1  Coque rigide Bleu lagon pour ALCATEL OT / 6033...   \n",
       "2  Facades et coques CELLULAR LINE SHCKGALS 3 MIN...   \n",
       "3               Coque meteore TPU  LG Nexus 4 / E960   \n",
       "4  Coque souple Transparente pour LG G FLEX D959 ...   \n",
       "\n",
       "                                            Libelle         Marque  \\\n",
       "0                Batterie Acer Aspire One 751H-52Yr         AUCUNE   \n",
       "1  Coque rigide Bleu lagon pour ALCATEL OT / 6033 …        MUZZANO   \n",
       "2  Facades et coques CELLULAR LINE SHCKGALS 3 MINIP  CELLULAR LINE   \n",
       "3              Coque meteore TPU  LG Nexus 4 / E960         AUCUNE   \n",
       "4  Coque souple Transparente pour LG G FLEX D959 m…        MUZZANO   \n",
       "\n",
       "                                 Description_cleaned  \n",
       "0  batter acer aspir one h yr li ion v mah wh noi...  \n",
       "1  coqu rigid bleu lagon alcatel ot motif drapeau...  \n",
       "2  facad coqu cellular lin shckgal minip marqu ag...  \n",
       "3                         coqu meteor tpu lg nexus e  \n",
       "4  coqu soupl transparent lg g flex motif keep ca...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CleanText()\n",
    "data = pd.read_csv(\"data/cdiscount_train.csv.zip\",sep=\",\", nrows=100000)\n",
    "ct.clean_df_column(data, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data.shape[0])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 219/50000 [00:00<00:22, 2182.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 50000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:18<00:00, 2688.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is composed of 50000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Categorie2</th>\n",
       "      <th>Categorie3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</td>\n",
       "      <td>ELECTRICITE  DOMOTIQUE</td>\n",
       "      <td>MULTIPRISE - RALLONGE - ENROULEUR</td>\n",
       "      <td>Rallonge CEE avec inverseur de phase 25 m 16 A...</td>\n",
       "      <td>Rallonge CEE avec inverseur de phase 25 m 16 A</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>rallong ce inverseur phas rallong ce haut qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DECO - LINGE - LUMINAIRE</td>\n",
       "      <td>OBJET DE DECORATION - BIBELOT</td>\n",
       "      <td>BUSTE - MANNEQUIN</td>\n",
       "      <td>Sun d’koh - Buste de Bouddha sur socle - cimen...</td>\n",
       "      <td>Sun d’koh - Buste de Bouddha sur socle - ciment…</td>\n",
       "      <td>SUN D’KOH</td>\n",
       "      <td>sun dkoh bust bouddh socl ciment cm tet bouddh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HYGIENE - BEAUTE - PARFUM</td>\n",
       "      <td>NAIL ART</td>\n",
       "      <td>STICKERS - AUTOCOLLANT - STRASS - PAILLETTES -...</td>\n",
       "      <td>La planche contient 24 motifs Support : ongle ...</td>\n",
       "      <td>STICKERS COLLIER STRASS FLEUR ONGLE ADHESIF</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>planch contient motif support ongle naturel ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIBRAIRIE</td>\n",
       "      <td>AUTRES LIVRES</td>\n",
       "      <td>AUTRES LIVRES</td>\n",
       "      <td>De Blodwenn Mauffret aux éditions IBIS ROUGE</td>\n",
       "      <td>LE CARNAVAL DE CAYENNE</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>blodwen mauffret edit ibis roug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VETEMENTS - LINGERIE</td>\n",
       "      <td>ACCESSOIRE MODE</td>\n",
       "      <td>CHAPEAU - BOB</td>\n",
       "      <td>Chapeau  - Casquette béret Modèle féminin et t...</td>\n",
       "      <td>Chapeau ... TU</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>chapeau casquet beret model feminin tendanc mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Categorie1                     Categorie2  \\\n",
       "0  BRICOLAGE - OUTILLAGE - QUINCAILLERIE        ELECTRICITE  DOMOTIQUE   \n",
       "1               DECO - LINGE - LUMINAIRE  OBJET DE DECORATION - BIBELOT   \n",
       "2              HYGIENE - BEAUTE - PARFUM                       NAIL ART   \n",
       "3                              LIBRAIRIE                  AUTRES LIVRES   \n",
       "4                  VETEMENTS - LINGERIE                 ACCESSOIRE MODE   \n",
       "\n",
       "                                          Categorie3  \\\n",
       "0                  MULTIPRISE - RALLONGE - ENROULEUR   \n",
       "1                                  BUSTE - MANNEQUIN   \n",
       "2  STICKERS - AUTOCOLLANT - STRASS - PAILLETTES -...   \n",
       "3                                      AUTRES LIVRES   \n",
       "4                                     CHAPEAU - BOB    \n",
       "\n",
       "                                         Description  \\\n",
       "0  Rallonge CEE avec inverseur de phase 25 m 16 A...   \n",
       "1  Sun d’koh - Buste de Bouddha sur socle - cimen...   \n",
       "2  La planche contient 24 motifs Support : ongle ...   \n",
       "3       De Blodwenn Mauffret aux éditions IBIS ROUGE   \n",
       "4  Chapeau  - Casquette béret Modèle féminin et t...   \n",
       "\n",
       "                                            Libelle     Marque  \\\n",
       "0    Rallonge CEE avec inverseur de phase 25 m 16 A     AUCUNE   \n",
       "1  Sun d’koh - Buste de Bouddha sur socle - ciment…  SUN D’KOH   \n",
       "2       STICKERS COLLIER STRASS FLEUR ONGLE ADHESIF     AUCUNE   \n",
       "3                            LE CARNAVAL DE CAYENNE     AUCUNE   \n",
       "4                                    Chapeau ... TU     AUCUNE   \n",
       "\n",
       "                                 Description_cleaned  \n",
       "0  rallong ce inverseur phas rallong ce haut qual...  \n",
       "1  sun dkoh bust bouddh socl ciment cm tet bouddh...  \n",
       "2  planch contient motif support ongle naturel ca...  \n",
       "3                    blodwen mauffret edit ibis roug  \n",
       "4  chapeau casquet beret model feminin tendanc mo...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"data/cdiscount_test.csv.zip\",sep=\",\")\n",
    "ct.clean_df_column(data_test, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data_test.shape[0])\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = sms.train_test_split(data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def vect_sequence(data_array):\n",
    "    data_array = [line.split(\"\") for line in data_array[\"Description_cleaned\"].values]\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "    data_vec = vec.fit_transform(data_array)\n",
    "    \n",
    "    return data_vec\n",
    "\n",
    "data_vec_train = vect_sequence(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<90000x59227 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1147126 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_method = Vectorizer(vectorizer_type = \"tfidf\", nb_hash = None )\n",
    "vec, feathash, data_train_vec = vect_method.vectorizer_train(data_train, columns = \"Description_cleaned\")\n",
    "data_valid_vec = vect_method.apply_vectorizer(data_valid, columns = \"Description_cleaned\", vec = vec, feathash = feathash)\n",
    "data_test_vec = vect_method.apply_vectorizer(data_test, columns = \"Description_cleaned\", vec = vec, feathash = feathash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 59227)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "int_to_label = {k:v for k,v in enumerate(set(Y_train))}\n",
    "label_to_int = {v:k for k,v in int_to_label.items()}\n",
    "Y_train = data_train.Categorie1.values\n",
    "Y_train_int = np.array([label_to_int[y] for y in Y_train]).reshape(len(Y_train),1)\n",
    "Y_valid = data_valid.Categorie1.values\n",
    "Y_valid_int = np.array([label_to_int[y] for y in Y_valid]).reshape(len(Y_valid),1)\n",
    "Y_test = data_test.Categorie1.values\n",
    "Y_test_int = np.array([label_to_int[y] for y in Y_test]).reshape(len(Y_test),1)\n",
    "N_label = len(int_to_label)\n",
    "print(N_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_9 (SimpleRNN)     (None, 28, 100)           40100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 100)           400       \n",
      "_________________________________________________________________\n",
      "simple_rnn_10 (SimpleRNN)    (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 44)                2244      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 44)                0         \n",
      "=================================================================\n",
      "Total params: 50,294\n",
      "Trainable params: 50,094\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "90000/90000 [==============================] - 12s 135us/sample - loss: 2.2500 - accuracy: 0.4216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-dbc07ed0651e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=100 ,activation=\"relu\", input_shape=(28, 300), return_sequences=True))\n",
    "model.add(kl.BatchNormalization())\n",
    "model.add(kl.SimpleRNN(units=50 ,activation=\"relu\"))\n",
    "model.add(kl.Dense(N_label))\n",
    "model.add(kl.Activation(\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "epochs = 500\n",
    "batch_size=256\n",
    "history = model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, Y_train_int, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=[X_valid, Y_valid_int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_token = [line.split(\" \") for line in data_train[\"Description_cleaned\"].values]\n",
    "valid_array_token = [line.split(\" \") for line in data_valid[\"Description_cleaned\"].values]\n",
    "test_array_token = [line.split(\" \") for line in data_test[\"Description_cleaned\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg_full = gensim.models.Word2Vec.load(\"data/w2v_model/full_model_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([28.]), 43)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(x) for x in train_array_token], q=[99]),max([len(x) for x in train_array_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/90000 [00:00<?, ?it/s]/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "100%|██████████| 90000/90000 [00:56<00:00, 1599.66it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4026.83it/s]\n",
      "100%|██████████| 50000/50000 [00:35<00:00, 1427.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def tokens_to_embedding_sequences(array_token, model):\n",
    "    array_embedding_sequences = []\n",
    "    for tokens in tqdm(array_token):\n",
    "        embedding_sequence = []\n",
    "        for token in tokens[:28]:\n",
    "             embedding_sequence.append(model[token])\n",
    "        array_embedding_sequences.append(embedding_sequence)\n",
    "    X = pad_sequences(array_embedding_sequences)\n",
    "    return X\n",
    "X_train = tokens_to_embedding_sequences(train_array_token, model_sg_full)\n",
    "X_valid = tokens_to_embedding_sequences(valid_array_token, model_sg_full)\n",
    "X_test = tokens_to_embedding_sequences(test_array_token, model_sg_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 256)               570368    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 44)                11308     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 44)                0         \n",
      "=================================================================\n",
      "Total params: 647,468\n",
      "Trainable params: 647,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "90000/90000 [==============================] - 51s 565us/sample - loss: 2.3863 - accuracy: 0.3647 - val_loss: 1.7544 - val_accuracy: 0.5462\n",
      "Epoch 2/500\n",
      "90000/90000 [==============================] - 53s 587us/sample - loss: 1.5995 - accuracy: 0.5836 - val_loss: 1.4644 - val_accuracy: 0.6238\n",
      "Epoch 3/500\n",
      "90000/90000 [==============================] - 50s 556us/sample - loss: 1.3591 - accuracy: 0.6515 - val_loss: 1.3129 - val_accuracy: 0.6648\n",
      "Epoch 4/500\n",
      "90000/90000 [==============================] - 52s 575us/sample - loss: 1.2022 - accuracy: 0.6924 - val_loss: 1.2110 - val_accuracy: 0.6920\n",
      "Epoch 5/500\n",
      "90000/90000 [==============================] - 52s 576us/sample - loss: 1.0962 - accuracy: 0.7183 - val_loss: 1.1657 - val_accuracy: 0.7030\n",
      "Epoch 6/500\n",
      "90000/90000 [==============================] - 51s 571us/sample - loss: 1.0224 - accuracy: 0.7353 - val_loss: 1.1373 - val_accuracy: 0.7122\n",
      "Epoch 7/500\n",
      "90000/90000 [==============================] - 52s 579us/sample - loss: 0.9632 - accuracy: 0.7495 - val_loss: 1.1068 - val_accuracy: 0.7232\n",
      "Epoch 8/500\n",
      "90000/90000 [==============================] - 52s 576us/sample - loss: 0.9115 - accuracy: 0.7618 - val_loss: 1.1220 - val_accuracy: 0.7226\n",
      "Epoch 9/500\n",
      "90000/90000 [==============================] - 51s 570us/sample - loss: 0.8714 - accuracy: 0.7721 - val_loss: 1.0850 - val_accuracy: 0.7302\n",
      "Epoch 10/500\n",
      "90000/90000 [==============================] - 52s 578us/sample - loss: 0.8255 - accuracy: 0.7828 - val_loss: 1.1006 - val_accuracy: 0.7311\n",
      "Epoch 11/500\n",
      "90000/90000 [==============================] - 51s 571us/sample - loss: 0.7870 - accuracy: 0.7920 - val_loss: 1.0813 - val_accuracy: 0.7398\n",
      "Epoch 12/500\n",
      "90000/90000 [==============================] - 53s 588us/sample - loss: 0.7575 - accuracy: 0.7988 - val_loss: 1.0786 - val_accuracy: 0.7413\n",
      "Epoch 13/500\n",
      "90000/90000 [==============================] - 52s 580us/sample - loss: 0.7283 - accuracy: 0.8060 - val_loss: 1.1044 - val_accuracy: 0.7395\n",
      "Epoch 14/500\n",
      "90000/90000 [==============================] - 52s 577us/sample - loss: 0.6990 - accuracy: 0.8128 - val_loss: 1.1369 - val_accuracy: 0.7424\n",
      "Epoch 15/500\n",
      "90000/90000 [==============================] - 52s 577us/sample - loss: 0.6835 - accuracy: 0.8182 - val_loss: 1.1421 - val_accuracy: 0.7403\n",
      "Epoch 16/500\n",
      "90000/90000 [==============================] - 53s 585us/sample - loss: 0.6547 - accuracy: 0.8248 - val_loss: 1.1600 - val_accuracy: 0.7426\n",
      "Epoch 17/500\n",
      "90000/90000 [==============================] - 52s 583us/sample - loss: 0.6312 - accuracy: 0.8301 - val_loss: 1.1716 - val_accuracy: 0.7440\n",
      "Epoch 18/500\n",
      "90000/90000 [==============================] - 52s 580us/sample - loss: 0.6077 - accuracy: 0.8358 - val_loss: 1.1936 - val_accuracy: 0.7456\n",
      "Epoch 19/500\n",
      "90000/90000 [==============================] - 53s 587us/sample - loss: 0.5810 - accuracy: 0.8430 - val_loss: 1.2101 - val_accuracy: 0.7464\n",
      "Epoch 20/500\n",
      "90000/90000 [==============================] - 52s 579us/sample - loss: 0.5982 - accuracy: 0.8410 - val_loss: 1.2306 - val_accuracy: 0.7433\n",
      "Epoch 21/500\n",
      "90000/90000 [==============================] - 54s 595us/sample - loss: 0.5734 - accuracy: 0.8485 - val_loss: 1.3854 - val_accuracy: 0.6960\n",
      "Epoch 22/500\n",
      "90000/90000 [==============================] - 55s 608us/sample - loss: 0.5803 - accuracy: 0.8423 - val_loss: 1.3616 - val_accuracy: 0.7439\n",
      "Epoch 23/500\n",
      "90000/90000 [==============================] - 49s 550us/sample - loss: 0.5242 - accuracy: 0.8583 - val_loss: 1.3038 - val_accuracy: 0.7458\n",
      "Epoch 24/500\n",
      "90000/90000 [==============================] - 48s 537us/sample - loss: 0.5010 - accuracy: 0.8639 - val_loss: 1.3380 - val_accuracy: 0.7465\n",
      "Epoch 25/500\n",
      "90000/90000 [==============================] - 49s 543us/sample - loss: 0.5288 - accuracy: 0.8622 - val_loss: 1.3276 - val_accuracy: 0.7479\n",
      "Epoch 26/500\n",
      "90000/90000 [==============================] - 48s 538us/sample - loss: 0.4712 - accuracy: 0.8722 - val_loss: 1.4195 - val_accuracy: 0.7439\n",
      "Epoch 27/500\n",
      "90000/90000 [==============================] - 48s 535us/sample - loss: 0.4568 - accuracy: 0.8758 - val_loss: 1.4533 - val_accuracy: 0.7454\n",
      "Epoch 28/500\n",
      "90000/90000 [==============================] - 48s 532us/sample - loss: 0.4449 - accuracy: 0.8792 - val_loss: 1.4442 - val_accuracy: 0.7429\n",
      "Epoch 29/500\n",
      "90000/90000 [==============================] - 47s 522us/sample - loss: 0.7544 - accuracy: 0.8322 - val_loss: 1.2569 - val_accuracy: 0.7460\n",
      "Epoch 30/500\n",
      "90000/90000 [==============================] - 48s 530us/sample - loss: 0.4536 - accuracy: 0.8760 - val_loss: 1.4018 - val_accuracy: 0.7446\n",
      "Epoch 31/500\n",
      "90000/90000 [==============================] - 48s 531us/sample - loss: 0.4261 - accuracy: 0.8837 - val_loss: 1.4711 - val_accuracy: 0.7442\n",
      "Epoch 32/500\n",
      "90000/90000 [==============================] - 47s 520us/sample - loss: 0.4402 - accuracy: 0.8800 - val_loss: 1.3867 - val_accuracy: 0.7382\n",
      "Epoch 33/500\n",
      "90000/90000 [==============================] - 47s 526us/sample - loss: 0.4572 - accuracy: 0.8765 - val_loss: 1.4386 - val_accuracy: 0.7470\n",
      "Epoch 34/500\n",
      "90000/90000 [==============================] - 47s 517us/sample - loss: 0.4097 - accuracy: 0.8885 - val_loss: 1.5235 - val_accuracy: 0.7460\n",
      "Epoch 35/500\n",
      "90000/90000 [==============================] - 47s 519us/sample - loss: 0.3875 - accuracy: 0.8945 - val_loss: 1.4999 - val_accuracy: 0.7457\n",
      "Epoch 36/500\n",
      "90000/90000 [==============================] - 47s 518us/sample - loss: 0.3767 - accuracy: 0.8969 - val_loss: 1.6315 - val_accuracy: 0.7454\n",
      "Epoch 37/500\n",
      "90000/90000 [==============================] - 47s 523us/sample - loss: 0.3690 - accuracy: 0.8996 - val_loss: 1.6666 - val_accuracy: 0.7426\n",
      "Epoch 38/500\n",
      "90000/90000 [==============================] - 47s 518us/sample - loss: 0.3593 - accuracy: 0.9018 - val_loss: 1.6384 - val_accuracy: 0.7434\n",
      "Epoch 39/500\n",
      "90000/90000 [==============================] - 47s 522us/sample - loss: 0.3553 - accuracy: 0.9026 - val_loss: 1.7335 - val_accuracy: 0.7389\n",
      "Epoch 40/500\n",
      "90000/90000 [==============================] - 47s 527us/sample - loss: 0.3463 - accuracy: 0.9054 - val_loss: 1.7013 - val_accuracy: 0.7392\n",
      "Epoch 41/500\n",
      "90000/90000 [==============================] - 47s 525us/sample - loss: 0.3478 - accuracy: 0.9042 - val_loss: 1.6554 - val_accuracy: 0.7353\n",
      "Epoch 42/500\n",
      "90000/90000 [==============================] - 46s 516us/sample - loss: 0.3360 - accuracy: 0.9073 - val_loss: 1.7908 - val_accuracy: 0.7422\n",
      "Epoch 43/500\n",
      "90000/90000 [==============================] - 56s 625us/sample - loss: 0.3298 - accuracy: 0.9091 - val_loss: 1.7171 - val_accuracy: 0.7440\n",
      "Epoch 44/500\n",
      "90000/90000 [==============================] - 51s 566us/sample - loss: 0.3257 - accuracy: 0.9106 - val_loss: 1.7628 - val_accuracy: 0.7420\n",
      "Epoch 45/500\n",
      "90000/90000 [==============================] - 45s 505us/sample - loss: 0.4771 - accuracy: 0.8696 - val_loss: 1.5462 - val_accuracy: 0.7434\n",
      "Epoch 46/500\n",
      "90000/90000 [==============================] - 46s 514us/sample - loss: 0.3427 - accuracy: 0.9053 - val_loss: 1.7038 - val_accuracy: 0.7447\n",
      "Epoch 47/500\n",
      "90000/90000 [==============================] - 45s 503us/sample - loss: 0.3137 - accuracy: 0.9141 - val_loss: 1.7766 - val_accuracy: 0.7426\n",
      "Epoch 48/500\n",
      "84480/90000 [===========================>..] - ETA: 2s - loss: 0.3021 - accuracy: 0.9168"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-27df5864483a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(units=256 ,activation=\"relu\", input_shape=(28, 300)))\n",
    "model.add(kl.Dense(256))\n",
    "model.add(kl.Activation(\"relu\"))\n",
    "model.add(kl.Dense(N_label))\n",
    "model.add(kl.Activation(\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "epochs = 500\n",
    "batch_size=256\n",
    "history = model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train_int, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=[X_valid, Y_valid_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
