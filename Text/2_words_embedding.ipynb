{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data : Cdiscount's product description.\n",
    "\n",
    "This dataset has been released from Cdiscount for a data competition (type kaggle) on the french website [datascience.net](https://www.datascience.net/fr/challenge). <br>\n",
    "The test dataset of this competition has not been released, so we used a subset of 1M producted of the original train dataset(+15M rows) all along the **Natural Language Processing** lab.<br>\n",
    "The objective of this competition was to classify the text description of various product into various categories that compose the navigation tree of Cdiscount website. It is composed of 4,733 categories organized within 44 meta categories. <br>\n",
    "\n",
    "The objective of this lab is not win the competition so we will only used the meta-categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Words embedding. Application to text classification and semi-supervised learning.\n",
    "\n",
    "In this first notebook we study three words embedding methods:\n",
    "\n",
    "* [Word2Vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "* [FastText](https://arxiv.org/pdf/1607.04606.pdf)\n",
    "* [Glove](https://nlp.stanford.edu/pubs/glove.pdf)\n",
    "\n",
    "We for each of these three method we will:\n",
    "\n",
    "* Study their characteristics\n",
    "* Explore the embedding they produces\n",
    "* Check how they perform on classification problems\n",
    "* Check how they can overcome problem with few labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Importation des librairies utilisÃ©es\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import pickle\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "import plotly.offline as pof\n",
    "import plotly.graph_objects as go\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.metrics as smet\n",
    "\n",
    "import sklearn.model_selection as sms\n",
    "from solution.clean import CleanText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "We download the train and test data and generate the same cleaned columns and the same train/validation split than part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "data = pd.read_csv(\"data/cdiscount_train.csv.zip\",sep=\",\", nrows=100000)\n",
    "ct.clean_df_column(data, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data.shape[0])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"data/cdiscount_test.csv.zip\",sep=\",\")\n",
    "ct.clean_df_column(data_test, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data_test.shape[0])\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "In this part, we will generate`Word2Vec` model thanks to the [**gensim**](https://radimrehurek.com/gensim/index.html) python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Word2Vec model\n",
    "\n",
    "The `gensim.models.Word2Vec` function allows to build  Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.Word2Vec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As many machine learning models, the `Word2Vec` function has a lot of parameters to set, here is some argument that will be fixed:\n",
    "\n",
    "\n",
    "* Features_dimension = 300 : It's the dimension of the features space (the hidden layer during training) that will be set.\n",
    "* min_count = 1 : The minimim number of occurence of a token to consider it for the model\n",
    "* windows = 5 : The max distance between a target word and the other word in the sentence to be considered as a neighbors.\n",
    "* hs = 0 \n",
    "* negative = 10\n",
    "* iter = 10 -> (best results, after testing 5,10,15,20,25,30)\n",
    "\n",
    "**Q** What are the arguments *hs* and *negative* for? What does the values set for tese argument implies??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dimension = 300\n",
    "min_count = 1\n",
    "window = 5\n",
    "hs = 0\n",
    "negative = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes list of tokens as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_token = [line.split(\" \") for line in data[\"Description_cleaned\"].values]\n",
    "test_array_token = [line.split(\" \") for line in data_test[\"Description_cleaned\"].values]\n",
    "array_token[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train two models with the help of the class `WordEmbedding` within the `word_embedding.py` file:\n",
    "\n",
    "* One **skip-sgram**, sg = 1\n",
    "* One **CBOW** model, sg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_embedding import WordEmbedding\n",
    "\n",
    "we_sg = WordEmbedding(word_embedding_type = \"word2vec\", \n",
    "                      args = dict(sentences = array_token, sg=1, hs=hs, negative=negative, min_count=min_count, size=features_dimension, window = window, iter=10))\n",
    "model_sg, training_time_sg = we_sg.train()\n",
    "print(\"Model Skip-gram trained in %.2f minutes\"%(training_time_sg/60))\n",
    "model_sg.save(\"data/w2v_model/model_sg_100k\")\n",
    "\n",
    "we_cbow = WordEmbedding(word_embedding_type = \"word2vec\", \n",
    "                      args = dict(sentences = array_token, sg=0, hs=hs, negative=negative, min_count=min_count, size=features_dimension, window = window, iter=10))\n",
    "model_cbow, training_time_cbow = we_cbow.train()\n",
    "print(\"Model CBOW trained in %.2f minutes\"%(training_time_cbow/60))\n",
    "model_cbow.save(\"data/w2v_model/model_cbow_100k\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Why don't we split train and validation dataset before training the models?\n",
    "\n",
    "**Q** What can you say about the learning time difference between theses two models? How do you explain the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained Model\n",
    "\n",
    "As for convolution model, ther exist pre-trained model on the internet. \n",
    "One of the most famous is probably the [`GoogleNewsVectors`](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) that has been trained over 100 billions of GoogleNews article. However this model is in english and can't be use for the Cdiscount dataset\n",
    "\n",
    "\n",
    "We will use here a model from the follwoing git project: [https://github.com/Kyubyong/wordvectors](https://github.com/Kyubyong/wordvectors)where model has been learn on   1Giga of wikipedia's article in **Skip-Gram** mode.\n",
    "\n",
    "You can download it by clicking on this [link](https://drive.google.com/file/d/0B0ZXk88koS2KM0pVTktxdG15TkE/view).  unzip it and download it within the data folder with this direction *fr/bin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_dir = \"data/fr/fr.bin\"\n",
    "model_pretrained = gensim.models.Word2Vec.load(model_pretrained_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Property\n",
    "\n",
    "\n",
    "We will now compare some properties of the three word2vec model we have:   (*CBOW*, *Skip-Gram* et the pre-trained model *online*)\n",
    "\n",
    "*Model that we have learn has been learned on tokenized words. Hence, we will need tokenized word to test their properties.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "stemmer=nltk.stem.SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most similar world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `most_similar`'s word function from **gensim** enables to retrieve the most similar words from a word or a combination of word.\n",
    "\n",
    "**Q** From this [documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) answer the following question:\n",
    "* What is the similarity measure used?\n",
    "* In which space is it computed ? \n",
    "* How the the function work when several words are passed in parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Word\n",
    "\n",
    "**Exercise** For each three models, display output of the `most_similar` word for the word `homme`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/w2v_homme.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare the output of he function with the models learned on cdiscount and the pre-trained model. What can you say about the quality of these outputs?\n",
    "\n",
    "**Q** What can you say about the output of the two models learned on cdiscount? \n",
    "\n",
    "**Exercice** Display now the output of the `most_similar`function for the word  *femme*. \n",
    "\n",
    "**Exercice** Display now the output of the `most_similar`function for words related specifically to the cdiscount dataset.  (ex. *xbox*, *pantalon*,..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinaison de mots\n",
    "\n",
    "**Exercise** For each three models display output of the `most_similar` word for this combinations of word `femme`+ `roi` - `homme`. (Use the  *positive* and  *negative* argument of the function). \n",
    "Comment the quality of the outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/w2v_combination.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Test other combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict output word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict `predict_output_word` function of **gensim** allows to predict word  from a word or a combination of word.\n",
    "**Exercice** for the three models, display prediction from common word (*homme*, *femme*) or word specifically related to the Cdiscount dataset (*coque*-*de*-*tÃ©lÃ©phone*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/w2v_predict_output.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Features\n",
    "\n",
    "We will now create features matrices from the **Word2Vec** model we just learn in order to predict product categories..\n",
    "\n",
    "The model created, allowed to generate a vector in the feature space for each word `x` with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = model_sg['homm']\n",
    "print(x_feature.shape)\n",
    "x_feature[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our problem, the product descriptions we want to categorize are represented by a list of cleaned tokens from the previous notebook. <br>\n",
    "From those list, there are various way to represent these description with the **Word2Vec** model\n",
    "\n",
    "1. Mean of the features' vector of each token in the description. \n",
    "2. Weighted mean of the features' vector of each token in the description where the weight are the number of occurence of each token within description\n",
    "3. Weighted mean of the features' vector of each token in the description where the weight are `TFIDI` weight\n",
    "4. etc...\n",
    "\n",
    "It's the second solution we will use here.\n",
    "\n",
    "Let's first split the data (with `random_state=42`) to obtain same split than in first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = sms.train_test_split(data, test_size=0.1, random_state=42)\n",
    "train_array_token = [line.split(\" \") for line in data_train[\"Description_cleaned\"].values]\n",
    "valid_array_token = [line.split(\" \") for line in data_valid[\"Description_cleaned\"].values]\n",
    "test_array_token = [line.split(\" \") for line in data_test[\"Description_cleaned\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Write a function that enable to generate a weighted mean of the feature's vector of the token within a description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load solution/get_feature_mean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_description = train_array_token[0]\n",
    "get_features_mean(token_description, model_sg).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of use, the functions allowing to build vectors from token list has been written within the `WordEmbedding` class of the `word_embedding.py`file\n",
    "* `get_features_mean` : retourne le vecteur moyen dans l'espace d'embedding, des projections des mots/tokens composant *lines*\n",
    "* `get_matrix_features_means` : applique la fonction `get_features_mean` sur tous les Ã©lÃ©ments de la matrice *X*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_train_cbow, embedded_conversion_train_time_cbow = WordEmbedding.get_matrix_features_means(train_array_token, model_cbow)\n",
    "X_embedded_valid_cbow, embedded_conversion_valid_time_cbow = WordEmbedding.get_matrix_features_means(valid_array_token, model_cbow)\n",
    "X_embedded_test_cbow, embedded_conversion_test_time_cbow = WordEmbedding.get_matrix_features_means(test_array_token, model_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_train_sg, embedded_conversion_train_time_sg = WordEmbedding.get_matrix_features_means(train_array_token, model_sg)\n",
    "X_embedded_valid_sg, embedded_conversion_valid_time_sg = WordEmbedding.get_matrix_features_means(valid_array_token, model_sg)\n",
    "X_embedded_test_sg, embedded_conversion_test_time_sg = WordEmbedding.get_matrix_features_means(test_array_token, model_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText(apply_stemming=False)\n",
    "ct.clean_df_column(data_train, \"Description\", \"Description_cleaned_no_stem\")\n",
    "ct.clean_df_column(data_valid, \"Description\", \"Description_cleaned_no_stem\")\n",
    "ct.clean_df_column(data_test, \"Description\", \"Description_cleaned_no_stem\")\n",
    "\n",
    "\n",
    "train_array_token_nostem = [line.split(\" \") for line in data_train[\"Description_cleaned_no_stem\"].values]\n",
    "valid_array_token_nostem = [line.split(\" \") for line in data_valid[\"Description_cleaned_no_stem\"].values]\n",
    "test_array_token_nostem = [line.split(\" \") for line in data_test[\"Description_cleaned_no_stem\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_train_pretrained, embedded_conversion_train_time_pretrained = WordEmbedding.get_matrix_features_means(train_array_token_nostem, model_pretrained)\n",
    "X_embedded_valid_pretrained, embedded_conversion_valid_time_pretrained = WordEmbedding.get_matrix_features_means(valid_array_token_nostem, model_pretrained)\n",
    "X_embedded_test_pretrained, embedded_conversion_test_time_pretrained = WordEmbedding.get_matrix_features_means(test_array_token_nostem, model_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product classification\n",
    "\n",
    "Now we have build the features, let's train variousn classifier model (the same than the one use in previous notebook) on this feature! \n",
    "\n",
    "The following code enable to train this model. Once again, model has already been trained, and results save in the `data/metadata/metadata_2.pkl`file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_TO_RUN = False\n",
    "\n",
    "from ml_model import MlModel\n",
    "\n",
    "we_models = [[model_sg, \"skip-gram\"],\n",
    "            [model_cbow, \"cbow\"],\n",
    "             [model_pretrained, \"pretrained\"]]\n",
    "\n",
    "model_parameters = [[\"lr\", {\"C\":[0.1, 1, 10]}],\n",
    "                     [\"rf\", {\"n_estimators\" : [100,500]}],\n",
    "                     [\"mlp\", {\"hidden_layer_sizes\" : [128, 256]}]\n",
    "                      ]\n",
    "\n",
    "if FORCE_TO_RUN:\n",
    "    metadata = {}\n",
    "    for we_model, we_name in we_models:\n",
    "        train_token = train_array_token if we_name !=\"pretrained\" else train_array_token_nostem\n",
    "        X_train, embedded_conversion_train_time = WordEmbedding.get_matrix_features_means(train_token, we_model)\n",
    "        Y_train = data_train.Categorie1.values\n",
    "        valid_token = valid_array_token if we_name !=\"pretrained\" else valid_array_token_nostem\n",
    "        X_valid, embedded_conversion_valid_time = WordEmbedding.get_matrix_features_means(valid_token, we_model)\n",
    "        Y_valid = data_valid.Categorie1.values\n",
    "        test_token = test_array_token if we_name !=\"pretrained\" else test_array_token_nostem\n",
    "        X_test, embedded_conversion_test_time = WordEmbedding.get_matrix_features_means(test_token, we_model)\n",
    "        Y_test = data_test.Categorie1.values\n",
    "\n",
    "        for ml_model_name, param_grid in model_parameters:\n",
    "            ml_class = MlModel(ml_model_name=ml_model_name, param_grid=param_grid)\n",
    "            best_model, best_metadata = ml_class.train_all_parameters(X_train, Y_train, X_valid, Y_valid, save_metadata=True)\n",
    "            test_score = best_model.score(X_test, Y_test)\n",
    "            accuracy_test = best_model.score(X_test, Y_test)\n",
    "            f1_macro_score_test = smet.f1_score(best_model.predict(X_test),Y_test, average='macro')\n",
    "            balanced_accuracy_test = smet.balanced_accuracy_score(best_model.predict(X_test),Y_test)\n",
    "            best_metadata.update({\"balanced_accuracy_test\":balanced_accuracy_test,\"accuracy_test\": accuracy_test, \"f1_macro_score_test\":f1_macro_score_test, \"embedded_conversion_train_time\": embedded_conversion_train_time, \"embedded_conversion_valid_time\": embedded_conversion_valid_time, \"embedded_conversion_test_time\": embedded_conversion_test_time})\n",
    "            metadata.update({(we_name, \"\",  ml_model_name): best_metadata})\n",
    "    pickle.dump(metadata, open(\"data/metadata/metadata_2.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pickle.load(open(\"data/metadata/metadata_1.pkl\",\"rb\"))\n",
    "metadata.update(pickle.load(open(\"data/metadata/metadata_2.pkl\",\"rb\")))\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "metrics = [\"accuracy_train\",'accuracy_valid', \"accuracy_test\", \"learning_time\", \"predict_time\",\"balanced_accuracy_test\",\"balanced_accuracy_valid\",\"balanced_accuracy_train\", \"f1_macro_score_test\", \"f1_macro_score_valid\", \"f1_macro_score_train\"]\n",
    "N_metrics = len(metrics)\n",
    "method_ml_names = ['lr','rf','mlp']\n",
    "N_method_ml_names = len(method_ml_names)\n",
    "\n",
    "buttons = []\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    for method_ml_name in method_ml_names:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[k[0]+\"_\"+str(k[1]) for k,v in metadata.items() if v['name']==method_ml_name],\n",
    "                y=[0 if ( not(k[0] in (\"skip-gram\",\"cbow\", \"pretrained\")) and metric.startswith(\"embedded\")) else v[metric] for k,v in metadata.items() if v['name']==method_ml_name],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=10),\n",
    "                name = method_ml_name,\n",
    "            )\n",
    "        )\n",
    "    buttons.append(\n",
    "            dict(label=metric,\n",
    "                 method=\"update\",\n",
    "                 args=[{\"visible\": [True if i in [i_metric*N_method_ml_names + k for k in range(N_method_ml_names)] else False for i in range(N_method_ml_names * N_metrics)]},\n",
    "                       {\"title\": metric}]))\n",
    "    \n",
    "\n",
    "# Update remaining layout properties\n",
    "fig.update_layout(\n",
    "    title_text=metric,\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=1,\n",
    "            buttons=buttons\n",
    "        )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What can you say about learning time for the different combination of *ML model X vectorisation/embedding* learned?\n",
    "\n",
    "**Q** What can you say about the values of these different metrics : `accuracy`, `balanced_accuracy`, `accuracy` for the different combination of *ML model X vectorisation/embedding* learned ?  Does theses results seem logical for you? \n",
    "\n",
    "**Q** What can you say about the optimized metrics?\n",
    "\n",
    "**Q** According to the best parameters selected for each metadata. What would you propose to do to omprove these results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi supervised learning.\n",
    "\n",
    "On the previous part we learn two words embedding models on the train dataset composed of 100.000 lines. (For ease of exploration, and running time). \n",
    "\n",
    "We have seen that Wor2vec does not necessarily perform better than simple vectorizer model. <br>\n",
    "But words embedding models required a lot of data to learned similarity between words. We used a pretrained model but it appears that our dataset is not really a natural **language dataset**. \n",
    "\n",
    "However one of the advantages of words embedding model is that they do not required labeled data to be trained. <br>\n",
    "Hence we will consider that we have the complete original train dataset of the Cdiscount context composed of 15M of lines, and we consider that it's an unlabeled dataset.<br> \n",
    "With the script `train_w2V_all_data.csv.py` we train two words2vec with the sames parameters than the model learned above. <br>\n",
    "\n",
    "Let's see how these new training performs in different usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg_full = gensim.models.Word2Vec.load(\"data/w2v_model/full_model_sg\")\n",
    "model_cbow_full = gensim.models.Word2Vec.load(\"data/w2v_model/full_model_cbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Does these models performs differently on the different function tests before such that `most_similar_word`, `predict_output_word`, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_TO_RUN=False\n",
    "\n",
    "from ml_model import MlModel\n",
    "\n",
    "we_models = [[model_sg_full, \"skip-gram\"],\n",
    "            [model_cbow_full, \"cbow\"]]\n",
    "\n",
    "model_parameters = [[\"lr\", {\"C\":[0.1, 1, 10]}],\n",
    "                     [\"rf\", {\"n_estimators\" : [100,500]}],\n",
    "                     [\"mlp\", {\"hidden_layer_sizes\" : [128, 256]}]\n",
    "                      ]\n",
    "\n",
    "if FORCE_TO_RUN:\n",
    "    metadata = {}\n",
    "    for we_model, we_name in we_models:\n",
    "        train_token = train_array_token if we_name !=\"pretrained\" else train_array_token_nostem\n",
    "        X_train, embedded_conversion_train_time = WordEmbedding.get_matrix_features_means(train_token, we_model)\n",
    "        Y_train = data_train.Categorie1.values\n",
    "        valid_token = valid_array_token if we_name !=\"pretrained\" else valid_array_token_nostem\n",
    "        X_valid, embedded_conversion_valid_time = WordEmbedding.get_matrix_features_means(valid_token, we_model)\n",
    "        Y_valid = data_valid.Categorie1.values\n",
    "        test_token = test_array_token if we_name !=\"pretrained\" else test_array_token_nostem\n",
    "        X_test, embedded_conversion_test_time = WordEmbedding.get_matrix_features_means(test_token, we_model)\n",
    "        Y_test = data_test.Categorie1.values\n",
    "\n",
    "        for ml_model_name, param_grid in model_parameters:\n",
    "            ml_class = MlModel(ml_model_name=ml_model_name, param_grid=param_grid)\n",
    "            best_model, best_metadata = ml_class.train_all_parameters(X_train, Y_train, X_valid, Y_valid, save_metadata=True)\n",
    "            accuracy_test = best_model.score(X_test, Y_test)\n",
    "            f1_macro_score_test = smet.f1_score(best_model.predict(X_test),Y_test, average='macro')\n",
    "            balanced_accuracy_test = smet.balanced_accuracy_score(best_model.predict(X_test),Y_test)\n",
    "            best_metadata.update({\"balanced_accuracy_test\":balanced_accuracy_test,\"accuracy_test\": accuracy_test, \"f1_macro_score_test\":f1_macro_score_test, \n",
    "                                  \"embedded_conversion_train_time\": embedded_conversion_train_time, \"embedded_conversion_valid_time\": embedded_conversion_valid_time, \"embedded_conversion_test_time\": embedded_conversion_test_time})\n",
    "            metadata.update({(we_name+\"_full\", \"\",  ml_model_name): best_metadata})\n",
    "    pickle.dump(metadata, open(\"data/metadata/metadata_2bis.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pickle.load(open(\"data/metadata/metadata_1.pkl\",\"rb\"))\n",
    "metadata.update(pickle.load(open(\"data/metadata/metadata_2.pkl\",\"rb\")))\n",
    "metadata.update(pickle.load(open(\"data/metadata/metadata_2bis.pkl\",\"rb\")))\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "metrics = [\"accuracy_train\",'accuracy_valid', \"accuracy_test\", \"learning_time\", \"predict_time\",\"balanced_accuracy_test\",\"balanced_accuracy_valid\",\"balanced_accuracy_train\", \"f1_macro_score_test\", \"f1_macro_score_valid\", \"f1_macro_score_train\"]\n",
    "N_metrics = len(metrics)\n",
    "method_ml_names = ['lr','rf','mlp']\n",
    "N_method_ml_names = len(method_ml_names)\n",
    "\n",
    "buttons = []\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    for method_ml_name in method_ml_names:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[k[0]+\"_\"+str(k[1]) for k,v in metadata.items() if v['name']==method_ml_name],\n",
    "                y=[0 if ( not(k[0] in (\"skip-gram\",\"cbow\", \"pretrained\")) and metric.startswith(\"embedded\")) else v[metric] for k,v in metadata.items() if v['name']==method_ml_name],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=10),\n",
    "                name = method_ml_name,\n",
    "            )\n",
    "        )\n",
    "    buttons.append(\n",
    "            dict(label=metric,\n",
    "                 method=\"update\",\n",
    "                 args=[{\"visible\": [True if i in [i_metric*N_method_ml_names + k for k in range(N_method_ml_names)] else False for i in range(N_method_ml_names * N_metrics)]},\n",
    "                       {\"title\": metric}]))\n",
    "    \n",
    "\n",
    "# Update remaining layout properties\n",
    "fig.update_layout(\n",
    "    title_text=metric,\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=1,\n",
    "            buttons=buttons\n",
    "        )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[('skip-gram_full', '', 'mlp')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "**Q** Comment the results with w2v features learned over the complete unlabeled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few labeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that training WordEmbedding dataset on an unsupervised dataset can improve the results of the classification (supervised) problem. \n",
    "\n",
    "However 100.000 is already a high number of rows and the difference of the different metrics using the full words embedding model or the other words embedding model is not high.\n",
    "\n",
    "TO see how it can performe in a situation where we are a very small labeled dataset; let's re run model for different size of training dataset for the best model combination parameters for the three metrics studied and for one words emebdding (full an simple) and one vectorizer model. ie:\n",
    "\n",
    "**accuracy**\n",
    "* *Word Embedding* : [[model_sg, \"skip-gram\"], [\"mlp\", {\"hidden_layer_sizes\": 256}]]\n",
    "* *Word Embedding full* : [[model_sg_full, \"skip-gram-full\"], [\"mlp\", {\"hidden_layer_sizes\": 256}]]\n",
    "* *Vectorizer: [[tfidf,'None'], ['lr', {\"C\":10}]]\n",
    "\n",
    "**balanced accuracy**\n",
    "* *Word Embedding*: accuracy_test = [[model_sg, \"skip-gram\"], [\"rf\", {\"n_estimators\": 500}]]\n",
    "* *Word Embedding full*: accuracy_test = [[model_sg_full, \"skip-gram-full\"], [\"rf\", {\"n_estimators\": 500}]]\n",
    "* *Vectorizer: [[tfidf,'None'], ['lr', {\"C\":10}]]\n",
    "\n",
    "**f1 macro score**\n",
    "* *Word Embedding* : [[model_sg, \"skip-gram\"], [\"mlp\", {\"hidden_layer_sizes\": 256}]]\n",
    "* *Word Embedding full* : [[model_sg_full, \"skip-gram-full\"], [\"mlp\", {\"hidden_layer_sizes\": 256}]]\n",
    "* *Vectorizer: [[tfidf,'mlp'], [\"hidden_layer_sizes\": [256]]]\n",
    "\n",
    "*You may have to change these values if the results are different for you*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "The following line allows to train the different models defined above on different train size of dataset.<br>\n",
    "In order to save time, the model have already been trained, and data saved within the `data/metadata/metadata_few_labeled_dataset.pkl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_TO_RUN = False\n",
    "from ml_model import MlModel\n",
    "from vectorizer import Vectorizer\n",
    "\n",
    "args = [[\"we\", [\"skip-gram_full\", model_sg_full, ], [\"rf\", {\"n_estimators\": [500]}]],\n",
    "        [\"we\", [\"skip-gram_full\", model_sg_full, ], [\"mlp\", {\"hidden_layer_sizes\": [256]}]],\n",
    "        [\"we\", [\"skip-gram\", model_sg, ], [\"rf\", {\"n_estimators\": [500]}]],\n",
    "        [\"we\", [\"skip-gram\", model_sg, ], [\"mlp\", {\"hidden_layer_sizes\": [256]}]],\n",
    "        [\"vect\", [\"tfidf\", \"None\"], [\"mlp\", {\"hidden_layer_sizes\": [256]}]],\n",
    "         [\"vect\", [\"tfidf\", \"None\"], [\"lr\", {\"C\": [10]}]]]\n",
    "train_sizes = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "if FORCE_TO_RUN:\n",
    "    metadata = {}\n",
    "    for vect_type, (vect_name, vect_arg), (ml_model_name, param_grid) in args:\n",
    "        for train_size in train_sizes:\n",
    "            print(vect_name, ml_model_name, train_size)\n",
    "            if vect_type == \"we\":\n",
    "                we_model = vect_arg\n",
    "                train_token = train_array_token[:train_size] \n",
    "                X_train, embedded_conversion_train_time = WordEmbedding.get_matrix_features_means(train_token, we_model)\n",
    "                valid_token = valid_array_token\n",
    "                X_valid, embedded_conversion_valid_time = WordEmbedding.get_matrix_features_means(valid_token, we_model)\n",
    "                test_token = test_array_token\n",
    "                X_test, embedded_conversion_test_time = WordEmbedding.get_matrix_features_means(test_token, we_model)\n",
    "            else:\n",
    "                nb_hash = vect_arg\n",
    "                vect_method = Vectorizer(vectorizer_type=vect_name, nb_hash=nb_hash)\n",
    "                X_train = vect_method.load_dataframe(\"train\")[:train_size]\n",
    "                X_valid = vect_method.load_dataframe(\"valid\")\n",
    "                X_test = vect_method.load_dataframe(\"test\")\n",
    "\n",
    "            Y_train = data_train.Categorie1.values[:train_size]\n",
    "            Y_valid = data_valid.Categorie1.values\n",
    "            Y_test = data_test.Categorie1.values\n",
    "\n",
    "            # model\n",
    "            ml_class = MlModel(ml_model_name=ml_model_name, param_grid=param_grid)\n",
    "            best_model, best_metadata = ml_class.train_all_parameters(X_train, Y_train, X_valid, Y_valid, save_metadata=True)\n",
    "            accuracy_test = best_model.score(X_test, Y_test)\n",
    "            f1_macro_score_test = smet.f1_score(best_model.predict(X_test),Y_test, average='macro')\n",
    "            balanced_accuracy_test = smet.balanced_accuracy_score(best_model.predict(X_test),Y_test)\n",
    "            best_metadata.update({\"balanced_accuracy_test\": balanced_accuracy_test, \"accuracy_test\": accuracy_test,\n",
    "                                  \"f1_macro_score_test\": f1_macro_score_test,\n",
    "                                  \"embedded_conversion_train_time\": embedded_conversion_train_time,\n",
    "                                  \"embedded_conversion_valid_time\": embedded_conversion_valid_time,\n",
    "                                  \"embedded_conversion_test_time\": embedded_conversion_test_time})\n",
    "            metadata.update({(vect_name, ml_model_name, train_size): best_metadata})\n",
    "            pickle.dump(metadata, open(\"data/metadata/metadata_few_labeled_dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pickle.load(open(\"data/metadata/metadata_few_labeled_dataset.pkl\", \"rb\"))\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "metrics = [\"accuracy_train\",'accuracy_valid', \"accuracy_test\", \"learning_time\", \"predict_time\",\"balanced_accuracy_test\",\"balanced_accuracy_valid\",\"balanced_accuracy_train\", \"f1_macro_score_test\", \"f1_macro_score_valid\", \"f1_macro_score_train\"]\n",
    "N_metrics = len(metrics)\n",
    "method_vect_ml_names = [['skip-gram_full','rf'],['skip-gram_full','mlp'],['skip-gram','rf'],['skip-gram','mlp'],[\"tfidf\",\"lr\"],[\"tfidf\",\"mlp\"]]\n",
    "N_method_vect_ml_names = len(method_vect_ml_names)\n",
    "\n",
    "buttons = []\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    for vect_name, ml_name in method_vect_ml_names:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=  train_sizes,\n",
    "                y= [metadata[(vect_name,ml_name, x)][metric] for x in train_sizes],\n",
    "                mode=\"markers+lines\",\n",
    "                marker=dict(size=10),\n",
    "                name = vect_name+\"_\"+ml_name,\n",
    "            )\n",
    "        )\n",
    "    buttons.append(\n",
    "            dict(label=metric,\n",
    "                 method=\"update\",\n",
    "                 args=[{\"visible\": [True if i in [i_metric*N_method_ml_names + k for k in range(N_method_vect_ml_names)] else False for i in range(N_method_vect_ml_names * N_metrics)]},\n",
    "                       {\"title\": metric}]))\n",
    "    \n",
    "\n",
    "# Update remaining layout properties\n",
    "fig.update_layout(\n",
    "    xaxis_type=\"log\",\n",
    "    title_text=metric,\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=1,\n",
    "            buttons=buttons\n",
    "        )]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText\n",
    "\n",
    "`FastText` is an extension of Word2Vec propose by the same authors. It works quite the same that gensim but words are represented as subwords of n character. \n",
    "\n",
    "It is not usefull here as we do not really handle Natural Language processing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.FastText?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use the different codes above to train words embedding model using `FastText`instead of `word2vec`. \n",
    "Compare performance of word prediction, product classification or for the Defi-IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove\n",
    "\n",
    "Glove is an algorithm developed by [Standford's researcher](https://nlp.stanford.edu/projects/glove/) in [C language](https://github.com/stanfordnlp/GloVe). There is no standard python library widely used so far. \n",
    "\n",
    "For ease of use we will use the code developed [here](https://github.com/WenchenLi/GloVePyWrapper). The authors developed a python class called `GloveWrapper`that allows to call C original code in python. <br>\n",
    "This repo has been added to the *ÃA-Frameworks* and can be imported easily on this notebook (see codes below).\n",
    "\n",
    "To train model, the code requires a file with all text with no punctuation and word separate from each other by a blank space. The code below enables to generate such a file from the original cdiscount dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "data = pd.read_csv(\"data/cdiscount_train.csv.zip\",sep=\",\")\n",
    "ct.clean_df_column(data, \"Description\", \"Description_cleaned\")\n",
    "data[\"Description_cleaned\"].to_csv(\"data/cdiscount_train_glove\", sep=\" \", index=False, quotechar=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO generate the model, we apply successively these three steps:\n",
    "* **vocab_count** : get all vocabulary and number of appearance of each words\n",
    "* **cooccur** : compute the co-occurence matrix.\n",
    "* **shuffle** : the train dataset\n",
    "* **glove** : train the model using glove algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GloVePyWrapper.glove_pywrapper import  GloveWrapper\n",
    "\n",
    "glove = GloveWrapper(\n",
    "    corpus =\"data/cdiscount_train_glove\" ,\n",
    "    name = \"cdiscount_train\" ,\n",
    "    train_dir = \"data/glove/\",\n",
    "    builddir='GloVePyWrapper/build',\n",
    "    vocab_min_count=1,\n",
    "    vector_size=300,\n",
    "    window_size=5)\n",
    "#prepare vocabulary count\n",
    "glove.vocab_count()\n",
    "#prepare co-occurrence matrix\n",
    "glove.cooccur()\n",
    "#reshuffle\n",
    "glove.shuffle()\n",
    "#glove train\n",
    "glove.glove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: What the `vocab_min_count`, `vector_size`, `window_size` arguments  are for? Open the python code and check the different arguments used by glove function.\n",
    "\n",
    "**Q**: For each of the four steps, check files that have been generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim`library does not contains code to train glove model. <br>\n",
    "However, once glove model has been trained, it can be loaded via gensim so that we can use the same function than other words embedding model such that `Word2vec`or `FastText` using `glove2word2vec`function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'data/glove/cdiscount_train_vectors.txt'\n",
    "word2vec_output_file = 'data/glove/cdiscount_train_vectors.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: As for fastText, use the different codes above to train words embedding model using `FastText`instead of `word2vec`. \n",
    "Compare performance of word prediction, product classification or for the Defi-IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {
    "height": "279px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
